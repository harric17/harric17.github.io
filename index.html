<!DOCTYPE html>
<html>
<head>
  <title>Class Project</title>
  <meta charset="utf-8">
  <meta name="description" content="Class Project">
  <meta name="author" content="Will Harris">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->  <link rel=stylesheet href="./assets/css/ribbons.css"></link>

  
  <!-- Grab CDN jQuery, fall back to local if offline -->
  <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
  <script>window.jQuery || document.write('<script src="libraries/widgets/quiz/js/jquery.js"><\/script>')</script> 
  <script data-main="libraries/frameworks/io2012/js/slides" 
    src="libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
  

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
        <slide class="title-slide segue nobackground">
  <hgroup class="auto-fadein">
    <h1>Class Project</h1>
    <h2>Practical Machine Learning, June 2014</h2>
    <p>Will Harris<br/></p>
  </hgroup>
  <article></article>  
</slide>
    

    <!-- SLIDES -->
    <slide class="" id="slide-1" style="background:;">
  <hgroup>
    <h2>Introduction</h2>
  </hgroup>
  <article data-timings="">
    <p>A significant challenge to today&#39;s data scientists is extracting meaningful insights from the large volumes of data that are continuously being collected from a variety of sources.   The goal of this analysis was to develop an accurate algorithm for predicting the manner of exercise being performed by 6 participants based on measurements collected from inexpensive personal activity sensors.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Methods</h2>
  </hgroup>
  <article data-timings="">
    <p>The training dataset contained 19622 observations across 160 variables.  The testing set contained 20 observations, though it did not contain information related to the outcome measure.  The outcome variable of interest, classe, is a categorical variable consisting of 5 different levels.   A random forest model was fit to predict this categorical outcome.</p>

<p>
There was substantial data management required for this analysis.  First, five variables were excluded as obvious noise: X, problem_id, raw_timestamp_part_1, raw_timestamp_part_2, and cvtd_timestamp.  Next, variables that had exclusively missing values in the test set were also excluded.  This resulted in a dataset with 55 predictor variables, two of which were factors with the remaining numeric. </p>

<p>The training dataset was then ultimately divided.  Using a random uniform number generator a small subset of exactly 3000 observations was created and used to train the random forest model.  The remaining data was set aside for further validation of the model.  Ultimately the smaller training subset contained levels of the factor variables that were not in the test data set, so the two factor variables were also excluded from the analysis.  A forest of 500 trees was created, and the number of variables randomly chosen at each split was left as the default value of 7.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>Results</h2>
  </hgroup>
  <article data-timings="">
    <p>The out of bag error rate for the resulting random forest model was 2.63%, or 97.37% accuracy.  Class errors for the out of bag data are displayed below in Table 1.</p>

<p>Table 1: Confusion matrix from OOB data</p>

<pre><code>##     A   B   C   D   E class.error
## A 851   1   1   0   1    0.003513
## B  18 535   9   0   1    0.049734
## C   0  12 514   2   0    0.026515
## D   1   0  22 469   2    0.050607
## E   0   1   2   6 552    0.016043
</code></pre>

<p>The random forest model performed similarly well on the validation dataset, predicting the outcome with 97.38% accuracy.  The top 10 variables in terms of importance for this forest are presented in Table 2 on the next slide.  On the test data set, 19 of 20 observations were correctly predicted.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>Results</h2>
  </hgroup>
  <article data-timings="">
    <p>Table 2: Top 10 variables by importance</p>

<pre><code>##                   importance
## roll_belt             161.67
## num_window            152.65
## pitch_forearm         114.70
## yaw_belt              106.52
## magnet_dumbbell_y     103.02
## magnet_dumbbell_z     101.39
## pitch_belt             93.01
## roll_forearm           73.85
## accel_dumbbell_y       71.35
## magnet_dumbbell_x      68.88
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Conclusions</h2>
  </hgroup>
  <article data-timings="">
    <p>Many potential predictors were excluded from this analysisand moreover the final model was trained on only about 15% of the available data.  Nonetheless a highly accurate model was constructed using random forests.  
</p>

<p>Going forward several more investigative analyses could be performed.  For example this data could be further explored using a complete case analysis, which would yeild information about the predictive importance of the variables that were excluded in this analysis due to a large number of missing values.  Another additional future analysis might be creating a random forest using only the most important variables to see if model accuracy was similarly high.  If so this would minimize the amount of data needed to be collected.  A third future analysis might involve ways of better trying to distinguish classes the model had problems with e.g. class D from class C (see Table 1).
</p>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>
  <div class="pagination pagination-small" id='io2012-ptoc' style="display:none;">
    <ul>
      <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=1 title='Introduction'>
         1
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=2 title='Methods'>
         2
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=3 title='Results'>
         3
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=4 title='Results'>
         4
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=5 title='Conclusions'>
         5
      </a>
    </li>
  </ul>
  </div>  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
  <!-- Load Javascripts for Widgets -->
  
  <!-- LOAD HIGHLIGHTER JS FILES -->
  <script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <!-- DONE LOADING HIGHLIGHTER JS FILES -->
   
  </html>